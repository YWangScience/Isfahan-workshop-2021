{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "CNN-ResNet-Classification-DR16Q-Workshop-Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJRaEqw0FBqW"
      },
      "source": [
        "# Tutorial 3: More Networks and More Areas\n",
        "# by Yu Wang"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyDpHHqfFBqY",
        "outputId": "9af0204d-c1ea-418c-8024-cc84f01ca621"
      },
      "source": [
        "# download data from kaggle\n",
        "# https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/\n",
        "\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvqd0DhnFBqZ",
        "outputId": "e24316b1-44a6-43a2-b623-e38129a33a50"
      },
      "source": [
        "! kaggle datasets download sdss-iii-iv -f dr16q-log-zvi-galaxy.h5\n",
        "! kaggle datasets download sdss-iii-iv -f dr16q-log-zvi-quasar.h5\n",
        "\n",
        "! unzip dr16q-log-zvi-galaxy.h5.zip\n",
        "! unzip dr16q-log-zvi-quasar.h5.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dr16q-log-zvi-galaxy.h5.zip to /content\n",
            " 99% 921M/934M [00:08<00:00, 122MB/s]\n",
            "100% 934M/934M [00:08<00:00, 118MB/s]\n",
            "Downloading dr16q-log-zvi-quasar.h5.zip to /content\n",
            "100% 11.8G/11.8G [04:17<00:00, 83.7MB/s]\n",
            "100% 11.8G/11.8G [04:17<00:00, 49.4MB/s]\n",
            "Archive:  dr16q-log-zvi-galaxy.h5.zip\n",
            "  inflating: dr16q-log-zvi-galaxy.h5  \n",
            "Archive:  dr16q-log-zvi-quasar.h5.zip\n",
            "  inflating: dr16q-log-zvi-quasar.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYxLGOqxFBqZ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import h5py\n",
        "import sys\n",
        "#sys.path.append('../')\n",
        "#from file_path import *\n",
        "\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, ConcatDataset, random_split\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "#from skorch.dataset import Dataset\n",
        "\n",
        "#import seaborn as sns\n",
        "#sns.set_theme(style=\"ticks\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-19T06:46:41.392135Z",
          "start_time": "2021-06-19T06:46:41.383186Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McGkBzuYFBqa",
        "outputId": "b6d45edf-8c4a-4c3c-c0e0-617091e6ae80"
      },
      "source": [
        "# load h5 data\n",
        "galaxy = h5py.File('./dr16q-log-zvi-galaxy.h5', 'r') \n",
        "quasar = h5py.File('./dr16q-log-zvi-quasar.h5', 'r') \n",
        "\n",
        "quasar.keys()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KeysViewHDF5 ['autoclass_dr14q', 'autoclass_pqn', 'bal_prob', 'class_person', 'deltachi2_pca', 'fiberid', 'flux', 'flux_norm', 'index', 'is_qso_dr12q', 'is_qso_final', 'is_qso_qn', 'mjd', 'plate', 'sdss_name', 'sn_median_all', 'thing_id', 'url', 'wavelength', 'wavelength_log', 'z', 'z_conf', 'z_dr12q', 'z_pca', 'z_pipe', 'z_qn', 'z_vi', 'zwarn_pca']>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdb8jIWJFBqb"
      },
      "source": [
        "# use all data\n",
        "# set same number of each class\n",
        "#feature = np.concatenate((galaxy['flux_norm'], quasar['flux_norm'], bal['flux_norm']))\n",
        "#label = np.concatenate((np.full((len(galaxy['flux_norm']), 1), 0), np.full((len(quasar['flux_norm']), 1), 1), np.full((len(bal['flux_norm']), 1), 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-19T06:46:41.641767Z",
          "start_time": "2021-06-19T06:46:41.402926Z"
        },
        "id": "7GaCOwRdFBqb"
      },
      "source": [
        "# set same number of each class\n",
        "\n",
        "#number = min(len(galaxy['plate']), len(quasar['plate']))\n",
        "#print(number)\n",
        "\n",
        "number = 3000 # for having a quick traning in the workshop, we adopt 3000 spetra of each class\n",
        "feature = np.concatenate((galaxy['flux_norm'][:number], quasar['flux_norm'][:number]))\n",
        "label = np.concatenate((np.full((number, 1), 0), np.full((number, 1), 1)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-19T06:46:43.436382Z",
          "start_time": "2021-06-19T06:46:41.932292Z"
        },
        "id": "CzAwX9TZFBqb"
      },
      "source": [
        "# split traning and test data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(feature ,label, test_size= 0.2,random_state = 42 )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-19T06:46:44.322146Z",
          "start_time": "2021-06-19T06:46:43.836104Z"
        },
        "id": "WnJQzrNwFBqc"
      },
      "source": [
        "X_train=torch.Tensor(X_train).unsqueeze(1)\n",
        "Y_train=torch.Tensor(Y_train).to(torch.long)\n",
        "\n",
        "X_test=torch.Tensor(X_test).unsqueeze(1)\n",
        "Y_test=torch.Tensor(Y_test).to(torch.long)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybUEJuWMFBqc"
      },
      "source": [
        "## FNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-19T06:46:44.331546Z",
          "start_time": "2021-06-19T06:46:44.324313Z"
        },
        "id": "HdVsYQENFBqd"
      },
      "source": [
        "class FNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 60, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv1d(60, 70,200),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2, stride=2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv1d(70, 36, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2, stride=2))\n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(17532, 900),\n",
        "            nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(900, 100),\n",
        "            nn.ReLU())\n",
        "        self.fc3 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.unsqueeze(1)\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5N1350IFBqe"
      },
      "source": [
        "net= FNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf50qfUnFBqe",
        "outputId": "440dbde7-4809-4dcc-fcae-9c05cc07ad26"
      },
      "source": [
        "## test\n",
        "x = torch.rand(1,1,4618)\n",
        "net(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0833, 0.0372]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQb3MheVFBqe"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDyQeYajFBqf"
      },
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
        "        super(Residual, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=201, padding=100, stride=stride)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=17, padding=8, stride=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        #self.fc = nn.Linear(in_features, out_features, bias=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        y2 = self.bn2(self.conv2(y1))\n",
        "        if self.conv3:\n",
        "            x = self.conv3(x)\n",
        "        return F.relu(y2+x)\n",
        "    \n",
        "    \n",
        "def resnet_block(in_channels, out_channels, num_residuals, stride=1):\n",
        "    blk = []\n",
        "    for i in range(num_residuals):\n",
        "        if i==0:\n",
        "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=stride))\n",
        "        else:\n",
        "            blk.append(Residual(out_channels, out_channels))\n",
        "    return nn.Sequential(*blk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRqaq2EHFBqf"
      },
      "source": [
        "net = nn.Sequential()\n",
        "net.add_module('resnet_block_1', resnet_block(in_channels=1, out_channels=32, num_residuals=9, stride=1))\n",
        "net.add_module('resnet_block_2', resnet_block(in_channels=32, out_channels=64, num_residuals=1, stride=2))\n",
        "net.add_module('resnet_block_3', resnet_block(in_channels=64, out_channels=32, num_residuals=1, stride=2))\n",
        "net.add_module('resnet_block_4', resnet_block(in_channels=32, out_channels=16, num_residuals=1, stride=2))\n",
        "net.add_module('flatten', nn.Flatten())\n",
        "net.add_module('fc1', nn.Sequential(nn.Linear(in_features=9248, out_features=3076, bias=True), nn.ReLU()))\n",
        "net.add_module('fc2', nn.Sequential(nn.Linear(in_features=3076, out_features=796, bias=True), nn.ReLU()))\n",
        "net.add_module('fc3', nn.Sequential(nn.Linear(in_features=796, out_features=199, bias=True), nn.ReLU()))\n",
        "net.add_module('fc4', nn.Linear(in_features=199, out_features=2, bias=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "MniJYH78FBqg"
      },
      "source": [
        "net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phJ059pRFBqg"
      },
      "source": [
        "## test\n",
        "x = torch.rand(1,1,4618)\n",
        "net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-19T06:46:44.371484Z",
          "start_time": "2021-06-19T06:46:44.333355Z"
        },
        "id": "EALPkvfVFBqh"
      },
      "source": [
        "#net.load_state_dict(torch.load(runs_path+'CNN-Classification-DR16Q.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3V_JzJ8FBqh"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ariU1AdDFBqh",
        "outputId": "096f5847-2662-4959-ca09-4a5cdc69979a"
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    net.cuda()\n",
        "    device = torch.device('cuda')\n",
        "    print ('USE GPU')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print ('USE CPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zec5_yS-FBqi"
      },
      "source": [
        "def accuracy(y_hat, y):\n",
        "    return (y_hat.argmax(dim=1) == y).float().mean().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyeOKV-CFBqi"
      },
      "source": [
        "loss = nn.CrossEntropyLoss() # include softmax and cross entropy\n",
        "optimizer = optim.AdamW(net.parameters(), lr=0.00003, betas=(0.9, 0.999), weight_decay=1e-4, amsgrad=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2tgSKLMFBqi"
      },
      "source": [
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "train_iter = DataLoader(TensorDataset(X_train, Y_train), batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRahbhbMFBqj",
        "outputId": "a50107b6-bd11-4e82-a576-d8f40042df8e"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    net.train() \n",
        "    start = time.time()\n",
        "    train_l_sum = 0.\n",
        "    train_acc_sum = 0.\n",
        "    for img, label in train_iter:\n",
        "        if use_gpu:\n",
        "            img, label =  img.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        predict = net(img)\n",
        "        l = loss(predict, label.view(-1))\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        train_l_sum += l.data.item()\n",
        "        train_acc_sum += accuracy(predict, label.view(-1))\n",
        "    \n",
        "    if ((epoch+1)%1 ==0):\n",
        "        net.eval() \n",
        "        print('Epoch:',epoch, 'Acc:',train_acc_sum / len(train_iter), 'Loss:',train_l_sum / len(train_iter) )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Acc: 0.5884046052631579 Loss: 0.6638532986766413\n",
            "Epoch: 1 Acc: 0.6959292763157895 Loss: 0.5634666587177076\n",
            "Epoch: 2 Acc: 0.7386924342105263 Loss: 0.5028381449611563\n",
            "Epoch: 3 Acc: 0.7592516447368421 Loss: 0.476529985666275\n",
            "Epoch: 4 Acc: 0.7693256578947368 Loss: 0.460521988962826\n",
            "Epoch: 5 Acc: 0.782483552631579 Loss: 0.44468317063231216\n",
            "Epoch: 6 Acc: 0.7888569078947368 Loss: 0.4376163639520344\n",
            "Epoch: 7 Acc: 0.7962582236842105 Loss: 0.42742776635446045\n",
            "Epoch: 8 Acc: 0.7966694078947368 Loss: 0.4268218137715992\n",
            "Epoch: 9 Acc: 0.813733552631579 Loss: 0.40741798987514094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MJYTfyKFBqj"
      },
      "source": [
        "## save net\n",
        "#torch.save(net.state_dict(), runs_path+'ResNet-Classification-DR16Q-Equally.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjl91kVKFBqj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wa9r6uVFBqj"
      },
      "source": [
        "## Accuracy of each test group\n",
        "\n",
        "net.eval()\n",
        "test_iter = DataLoader(TensorDataset(X_test, Y_test), batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "y_hats = np.array([])\n",
        "ys = np.array([])\n",
        "for img, label in test_iter:\n",
        "    ys = np.concatenate((ys,label.view(-1).numpy()))\n",
        "    if use_gpu:\n",
        "        img, label =  img.to(device), label.to(device)\n",
        "    y_hat = net(img)\n",
        "    y_hats = np.concatenate((y_hats,y_hat.cpu().argmax(dim=1).detach().numpy()))\n",
        "    \n",
        "\n",
        "y_hat_0 = np.array([True if item == 0 else False for item in y_hats])\n",
        "y_0 = np.array([True if item == 0 else False for item in ys])\n",
        "\n",
        "y_hat_1 = np.array([True if item == 1 else False for item in y_hats])\n",
        "y_1 = np.array([True if item == 1 else False for item in ys])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqmARS4nFBqk"
      },
      "source": [
        "print('galaxy:', np.sum(y_hat_0 & y_0)/np.sum(y_0))\n",
        "print('quasar:', np.sum(y_hat_1 & y_1)/np.sum(y_1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}