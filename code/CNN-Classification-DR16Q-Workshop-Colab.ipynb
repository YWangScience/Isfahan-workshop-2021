{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial 3: More Networks and More Areas\n",
    "# by Yu Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from kaggle\n",
    "# https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/\n",
    "\n",
    "! pip install kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle datasets download sdss-iii-iv -f dr16q-log-zvi-galaxy.h5\n",
    "! kaggle datasets download sdss-iii-iv -f dr16q-log-zvi-quasar.h5\n",
    "\n",
    "! unzip dr16q-log-zvi-galaxy.h5.zip\n",
    "! unzip dr16q-log-zvi-quasar.h5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from file_path import *\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, ConcatDataset, random_split\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "#from skorch.dataset import Dataset\n",
    "\n",
    "#import seaborn as sns\n",
    "#sns.set_theme(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T06:46:41.392135Z",
     "start_time": "2021-06-19T06:46:41.383186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['autoclass_dr14q', 'autoclass_pqn', 'bal_prob', 'class_person', 'deltachi2_pca', 'fiberid', 'flux', 'flux_norm', 'index', 'is_qso_dr12q', 'is_qso_final', 'is_qso_qn', 'mjd', 'plate', 'sdss_name', 'sn_median_all', 'thing_id', 'url', 'wavelength', 'wavelength_log', 'z', 'z_conf', 'z_dr12q', 'z_pca', 'z_pipe', 'z_qn', 'z_vi', 'zwarn_pca']>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load h5 data\n",
    "galaxy = h5py.File('./dr16q-log-zvi-galaxy.h5', 'r') \n",
    "quasar = h5py.File('./dr16q-log-zvi-quasar.h5', 'r') \n",
    "\n",
    "quasar.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all data\n",
    "# set same number of each class\n",
    "#feature = np.concatenate((galaxy['flux_norm'], quasar['flux_norm'], bal['flux_norm']))\n",
    "#label = np.concatenate((np.full((len(galaxy['flux_norm']), 1), 0), np.full((len(quasar['flux_norm']), 1), 1), np.full((len(bal['flux_norm']), 1), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T06:46:41.641767Z",
     "start_time": "2021-06-19T06:46:41.402926Z"
    }
   },
   "outputs": [],
   "source": [
    "# set same number of each class\n",
    "\n",
    "#number = min(len(galaxy['plate']), len(quasar['plate']))\n",
    "#print(number)\n",
    "\n",
    "number = 3000 # for having a quick traning in the workshop, we adopt 3000 spetra of each class\n",
    "feature = np.concatenate((galaxy['flux_norm'][:number], quasar['flux_norm'][:number]))\n",
    "label = np.concatenate((np.full((number, 1), 0), np.full((number, 1), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T06:46:43.436382Z",
     "start_time": "2021-06-19T06:46:41.932292Z"
    }
   },
   "outputs": [],
   "source": [
    "# split traning and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feature ,label, test_size= 0.2,random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T06:46:44.322146Z",
     "start_time": "2021-06-19T06:46:43.836104Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train=torch.Tensor(X_train).unsqueeze(1)\n",
    "Y_train=torch.Tensor(Y_train).to(torch.long)\n",
    "\n",
    "X_test=torch.Tensor(X_test).unsqueeze(1)\n",
    "Y_test=torch.Tensor(Y_test).to(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T06:46:44.331546Z",
     "start_time": "2021-06-19T06:46:44.324313Z"
    }
   },
   "outputs": [],
   "source": [
    "class FNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 60, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(60, 70,200),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(70, 36, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(17532, 900),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(900, 100),\n",
    "            nn.ReLU())\n",
    "        self.fc3 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(1)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= FNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0833, 0.0372]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "x = torch.rand(1,1,4618)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=201, padding=100, stride=stride)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=17, padding=8, stride=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        #self.fc = nn.Linear(in_features, out_features, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        y2 = self.bn2(self.conv2(y1))\n",
    "        if self.conv3:\n",
    "            x = self.conv3(x)\n",
    "        return F.relu(y2+x)\n",
    "    \n",
    "    \n",
    "def resnet_block(in_channels, out_channels, num_residuals, stride=1):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i==0:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=stride))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add_module('resnet_block_1', resnet_block(in_channels=1, out_channels=32, num_residuals=9, stride=1))\n",
    "net.add_module('resnet_block_2', resnet_block(in_channels=32, out_channels=64, num_residuals=1, stride=2))\n",
    "net.add_module('resnet_block_3', resnet_block(in_channels=64, out_channels=32, num_residuals=1, stride=2))\n",
    "net.add_module('resnet_block_4', resnet_block(in_channels=32, out_channels=16, num_residuals=1, stride=2))\n",
    "net.add_module('flatten', nn.Flatten())\n",
    "net.add_module('fc1', nn.Sequential(nn.Linear(in_features=9248, out_features=3076, bias=True), nn.ReLU()))\n",
    "net.add_module('fc2', nn.Sequential(nn.Linear(in_features=3076, out_features=796, bias=True), nn.ReLU()))\n",
    "net.add_module('fc3', nn.Sequential(nn.Linear(in_features=796, out_features=199, bias=True), nn.ReLU()))\n",
    "net.add_module('fc4', nn.Linear(in_features=199, out_features=2, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "x = torch.rand(1,1,4618)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T06:46:44.371484Z",
     "start_time": "2021-06-19T06:46:44.333355Z"
    }
   },
   "outputs": [],
   "source": [
    "#net.load_state_dict(torch.load(runs_path+'CNN-Classification-DR16Q.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE GPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "    device = torch.device('cuda')\n",
    "    print ('USE GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print ('USE CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss() # include softmax and cross entropy\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.00003, betas=(0.9, 0.999), weight_decay=1e-4, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "train_iter = DataLoader(TensorDataset(X_train, Y_train), batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Acc: 0.5884046052631579 Loss: 0.6638532986766413\n",
      "Epoch: 1 Acc: 0.6959292763157895 Loss: 0.5634666587177076\n",
      "Epoch: 2 Acc: 0.7386924342105263 Loss: 0.5028381449611563\n",
      "Epoch: 3 Acc: 0.7592516447368421 Loss: 0.476529985666275\n",
      "Epoch: 4 Acc: 0.7693256578947368 Loss: 0.460521988962826\n",
      "Epoch: 5 Acc: 0.782483552631579 Loss: 0.44468317063231216\n",
      "Epoch: 6 Acc: 0.7888569078947368 Loss: 0.4376163639520344\n",
      "Epoch: 7 Acc: 0.7962582236842105 Loss: 0.42742776635446045\n",
      "Epoch: 8 Acc: 0.7966694078947368 Loss: 0.4268218137715992\n",
      "Epoch: 9 Acc: 0.813733552631579 Loss: 0.40741798987514094\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    net.train() \n",
    "    start = time.time()\n",
    "    train_l_sum = 0.\n",
    "    train_acc_sum = 0.\n",
    "    for img, label in train_iter:\n",
    "        if use_gpu:\n",
    "            img, label =  img.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predict = net(img)\n",
    "        l = loss(predict, label.view(-1))\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        train_l_sum += l.data.item()\n",
    "        train_acc_sum += accuracy(predict, label.view(-1))\n",
    "    \n",
    "    if ((epoch+1)%1 ==0):\n",
    "        net.eval() \n",
    "        print('Epoch:',epoch, 'Acc:',train_acc_sum / len(train_iter), 'Loss:',train_l_sum / len(train_iter) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save net\n",
    "#torch.save(net.state_dict(), runs_path+'ResNet-Classification-DR16Q-Equally.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy of each test group\n",
    "\n",
    "net.eval()\n",
    "test_iter = DataLoader(TensorDataset(X_test, Y_test), batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "y_hats = np.array([])\n",
    "ys = np.array([])\n",
    "for img, label in test_iter:\n",
    "    ys = np.concatenate((ys,label.view(-1).numpy()))\n",
    "    if use_gpu:\n",
    "        img, label =  img.to(device), label.to(device)\n",
    "    y_hat = net(img)\n",
    "    y_hats = np.concatenate((y_hats,y_hat.cpu().argmax(dim=1).detach().numpy()))\n",
    "    \n",
    "\n",
    "y_hat_0 = np.array([True if item == 0 else False for item in y_hats])\n",
    "y_0 = np.array([True if item == 0 else False for item in ys])\n",
    "\n",
    "y_hat_1 = np.array([True if item == 1 else False for item in y_hats])\n",
    "y_1 = np.array([True if item == 1 else False for item in ys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('galaxy:', np.sum(y_hat_0 & y_0)/np.sum(y_0))\n",
    "print('quasar:', np.sum(y_hat_1 & y_1)/np.sum(y_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
